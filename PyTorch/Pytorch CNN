{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch CNN","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyND4P9veFsDYJHiMVgF3NLG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zIkTgBzj_XdP"},"source":["import numpy as np\r\n","import pandas as pd\r\n","from sklearn.metrics import accuracy_score\r\n","from torchvision.datasets import MNIST\r\n","from torchvision.transforms import Compose, ToTensor, Normalize\r\n","from torch.utils.data import DataLoader\r\n","from torch.nn import Conv2d, MaxPool2d, Linear, ReLU, Softmax, Module, CrossEntropyLoss\r\n","from torch.nn.init import kaiming_uniform_, xavier_uniform_\r\n","from torch.optim import SGD"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMtGTOICAkXJ"},"source":["class CNN(Module):\r\n","  def __init__(self, n_channels):\r\n","    super(CNN, self).__init__()\r\n","    #First hidden layer\r\n","    self.hidden1 = Conv2d(n_channels, 32, (3,3))\r\n","    kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\r\n","    self.act1 = ReLU()\r\n","    self.pool1 = MaxPool2d((2,2), stride=(2,2))\r\n","\r\n","    #Second hidden layer\r\n","    self.hidden2 = Conv2d(32, 32, (3,3))\r\n","    kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\r\n","    self.act2 = ReLU()\r\n","    self.pool2 = MaxPool2d((2,2), stride=(2,2))\r\n","\r\n","    #Third hidden layer\r\n","    self.hidden3 = Linear(5*5*32, 100)\r\n","    kaiming_uniform_(self.hidden3.weight, nonlinearity='relu')\r\n","    self.act3 = ReLU()\r\n","    \r\n","    #Output Layer\r\n","    self.hidden4 = Linear(100, 10)\r\n","    xavier_uniform_(self.hidden4.weight)\r\n","    self.act4 = Softmax(dim=1)\r\n","\r\n","  \r\n","  def forward(self, x):\r\n","    x = self.hidden1(x)\r\n","    x = self.act1(x)\r\n","    x = self.pool1(x)\r\n","\r\n","    # second hidden layer\r\n","    x = self.hidden2(x)\r\n","    x = self.act2(x)\r\n","    x = self.pool2(x)\r\n","\r\n","    # Flatten\r\n","    x = x.view(-1, 4*4*50)\r\n","\r\n","    # Third hidden layer\r\n","    x = self.hidden3(x)\r\n","    x = self.act3(x)\r\n","\r\n","    # Output Layer\r\n","    x = self.hidden4(x)\r\n","    x = self.act4(x)\r\n","    return x    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3k7sfToqCGqf"},"source":["def prep_data(path):\r\n","  # Defines several transformations to apply to the dataset. here, you convert to tensor and normalize\r\n","  trans = Compose([ToTensor(), Normalize((0.1307),(0.3081))])\r\n","  train = MNIST(path, train=True, download=True, transform=trans)\r\n","  test = MNIST(path, train=False, download=True, transform=trans)\r\n","\r\n","  # Prepare dataloaders\r\n","  train_dl = DataLoader(train, batch_size=64, shuffle=True)\r\n","  test_dl = DataLoader(test, batch_size=1024, shuffle=False)\r\n","  return train_dl, test_dl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVUrjPttE5ja"},"source":["def train_model(train_dl, model, epochs):\r\n","  step = 0\r\n","  criterion = CrossEntropyLoss()\r\n","  optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\r\n","  for epoch in range(epochs):\r\n","    for i, (inputs, targets) in enumerate(train_dl):\r\n","      # For every iternation, Inputs and targets will be an array of batch_size (64) examples\r\n","      optimizer.zero_grad()\r\n","      yhat = model(inputs)\r\n","      loss = criterion(yhat, targets)\r\n","      loss.backward()\r\n","      optimizer.step()\r\n","    print(f'Epoch {step}/{epochs}')\r\n","    step += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FltHe3yiFtWn"},"source":["# This is unlike Train (Where you don't have to take out the numpy array etc.).\r\n","# This is because you are dealing with accuracy here, whereas for Training you are dealing with Loss\r\n","# Hence, you obtain the results in a different way here: For evaulate you need to numpy array to obtain acc score but\r\n","# for train you simply need the tensors itself to calculate the loss\r\n","def evaluate_model(test_dl, model):\r\n","  preds, actuals = [], []\r\n","  for i, (inputs, targets) in enumerate(test_dl):\r\n","    yhat = model(inputs)\r\n","    yhat = yhat.detach().numpy()\r\n","    # Convert from tensor to numpy\r\n","    actual = targets.numpy()\r\n","    # Convert to class label\r\n","    yhat = np.argmax(yhat, axis=1)\r\n","    actual = actual.reshape((len(actual), 1))\r\n","    yhat = yhat.reshape((len(yhat), 1))\r\n","\r\n","    preds.append(yhat)\r\n","    actuals.append(actual)\r\n","    # Since you have batch size, you currently have separate arrays (1 array per batch size)\r\n","    # Hence, you want to combine all these arays to form a single array (So you can calculate the accuracy using all examples from test)\r\n","  preds, actuals = np.vstack(preds), np.vstack(actuals)\r\n","\r\n","  acc = accuracy_score(actuals, preds)\r\n","  return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AD5_YVInGl2G"},"source":["path = '~/.torch/datasets/mnist'\r\n","train_dl, test_dl = prep_data(path)\r\n","print(len(train_dl.dataset), len(test_dl.dataset))\r\n","\r\n","model = CNN(1)\r\n","train_model(train_dl, model, epochs=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYtnXyimG39l","executionInfo":{"status":"ok","timestamp":1612058766276,"user_tz":-480,"elapsed":4417,"user":{"displayName":"Alex C","photoUrl":"","userId":"12397117775642959911"}},"outputId":"1d536ac9-5dd6-4455-9104-f620b445f11c"},"source":["acc = evaluate_model(test_dl, model)\r\n","print(f\"Accuracy is: {acc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy is: 0.9881\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1t8jZbCnMJmL"},"source":[""],"execution_count":null,"outputs":[]}]}